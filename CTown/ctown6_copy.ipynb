{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/user/meepc\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import Hankel,Corrhankel,Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('~/data/ctown/dataset03.csv')\n",
    "df2 = pd.read_csv('~/data/ctown/dataset04.csv')\n",
    "\n",
    "train_normal = pd.concat((df1,df2[df2['ATT_FLAG']==0]),axis=0,ignore_index=True)\n",
    "train_attack = df2[df2['ATT_FLAG']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [col for col in train_normal.columns if col not in ['DATETIME','ATT_FLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normal = pd.DataFrame(index=train_normal.index, columns=sensors, data=scaler.fit_transform(train_normal[sensors]))\n",
    "X_attack = train_attack[sensors].reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hankel = Hankel()\n",
    "corrhankel = Corrhankel()\n",
    "lag = 60\n",
    "stride = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_normal,nolag_normal = corrhankel.fit(X_normal.to_numpy(),lag,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_attack,nolag_attack = corrhankel.fit(X_attack.to_numpy(),lag,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('~/data/ctown/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epasad with 1 cluster and no threshold tuning (training attack included in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.concat((df_test,train_attack),axis=0)\n",
    "X_test = pd.DataFrame(index=test_combined.index, columns=sensors, data=scaler.fit_transform(test_combined[sensors]))\n",
    "corr_test,nolag_test = corrhankel.fit(X_test.to_numpy(),lag,stride)\n",
    "Y_test = test_combined.loc[:,'ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,optimal_k=1,tune=False,corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7647058823529411\n",
      "Precision  0.7407407407407407\n",
      "Recall  0.8695652173913043\n",
      "F1-score  0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy  0.7764705882352941\n",
    "# Precision  0.7647058823529411\n",
    "# Recall  0.8478260869565217\n",
    "# F1-score  0.8041237113402062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.49958960328317376 Median : 0.5058823529411764 Min : 0.4588235294117647 Max : 0.5882352941176471\n",
      "precision - Mean: 0.6365706360063405 Median : 0.8333333333333334 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.08543983822042468 Median : 0.08695652173913043 Min : 0.0 Max : 0.30434782608695654\n",
      "f1 -        Mean: 0.14575586469868504 Median : 0.16 Min : 0.0 Max : 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + No threshold tuning (training attack mixed in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------number of clusters------ 2\n",
      "Accuracy  0.7529411764705882\n",
      "Precision  0.7659574468085106\n",
      "Recall  0.782608695652174\n",
      "F1-score  0.7741935483870968\n",
      "-------number of clusters------ 3\n",
      "Accuracy  0.7411764705882353\n",
      "Precision  0.75\n",
      "Recall  0.782608695652174\n",
      "F1-score  0.7659574468085107\n",
      "-------number of clusters------ 4\n",
      "Accuracy  0.788235294117647\n",
      "Precision  0.78\n",
      "Recall  0.8478260869565217\n",
      "F1-score  0.8125\n",
      "-------number of clusters------ 5\n",
      "Accuracy  0.7176470588235294\n",
      "Precision  0.6833333333333333\n",
      "Recall  0.8913043478260869\n",
      "F1-score  0.7735849056603774\n",
      "-------number of clusters------ 6\n",
      "Accuracy  0.7411764705882353\n",
      "Precision  0.6935483870967742\n",
      "Recall  0.9347826086956522\n",
      "F1-score  0.7962962962962964\n",
      "-------number of clusters------ 7\n",
      "Accuracy  0.6588235294117647\n",
      "Precision  0.6307692307692307\n",
      "Recall  0.8913043478260869\n",
      "F1-score  0.7387387387387386\n"
     ]
    }
   ],
   "source": [
    "fscores_k_1 = []\n",
    "for k in range(2,8):\n",
    "    sensor_models = []\n",
    "    sensor_predicted = []\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    for i,sens in enumerate(sensors):\n",
    "        train_normal = X_normal.loc[:,sens].values\n",
    "        train_attack = X_attack.loc[:,sens].values\n",
    "        model = Pipeline()\n",
    "        model.fit(train_normal,train_attack,lag,stride,optimal_k=k,tune=False,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T)\n",
    "        test = X_test.loc[:,sens].values\n",
    "        y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "        sensor_predicted.append(y_predicted)\n",
    "        accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "        precision.append(precision_score(y_actual,y_predicted))\n",
    "        recall.append(recall_score(y_actual,y_predicted))\n",
    "        fscore.append(f1_score(y_actual,y_predicted))\n",
    "        sensor_models.append(model)    \n",
    "    sensor_predicted = np.asarray(sensor_predicted)\n",
    "    y_predicted = np.any(sensor_predicted,axis=0).astype(int) \n",
    "    print(\"-------number of clusters------\", k)\n",
    "    print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "    print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "    print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "    print(\"F1-score \",f1_score(y_actual,y_predicted))\n",
    "    fscores_k_1.append(f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7741935483870968,\n",
       " 0.7659574468085107,\n",
       " 0.8125,\n",
       " 0.7735849056603774,\n",
       " 0.7962962962962964,\n",
       " 0.7387387387387386]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscores_k_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + No threshold tuning (No concat of training and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index=df_test.index, columns=sensors, data=scaler.fit_transform(df_test[sensors]))\n",
    "corr_test,nolag_test = corrhankel.fit(X_test.to_numpy(),lag,stride)\n",
    "Y_test = df_test.loc[:,'ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------number of clusters------ 2\n",
      "Accuracy  0.7205882352941176\n",
      "Precision  0.6388888888888888\n",
      "Recall  0.7931034482758621\n",
      "F1-score  0.7076923076923076\n",
      "-------number of clusters------ 3\n",
      "Accuracy  0.7058823529411765\n",
      "Precision  0.6451612903225806\n",
      "Recall  0.6896551724137931\n",
      "F1-score  0.6666666666666667\n",
      "-------number of clusters------ 4\n",
      "Accuracy  0.6617647058823529\n",
      "Precision  0.5833333333333334\n",
      "Recall  0.7241379310344828\n",
      "F1-score  0.6461538461538462\n",
      "-------number of clusters------ 5\n",
      "Accuracy  0.5882352941176471\n",
      "Precision  0.5102040816326531\n",
      "Recall  0.8620689655172413\n",
      "F1-score  0.641025641025641\n",
      "-------number of clusters------ 6\n",
      "Accuracy  0.6323529411764706\n",
      "Precision  0.5416666666666666\n",
      "Recall  0.896551724137931\n",
      "F1-score  0.6753246753246753\n",
      "-------number of clusters------ 7\n",
      "Accuracy  0.5735294117647058\n",
      "Precision  0.5\n",
      "Recall  0.9310344827586207\n",
      "F1-score  0.6506024096385543\n"
     ]
    }
   ],
   "source": [
    "fscores_k_2=[]\n",
    "for k in range(2,8):\n",
    "    sensor_models = []\n",
    "    sensor_predicted = []\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    for i,sens in enumerate(sensors):\n",
    "        train_normal = X_normal.loc[:,sens].values\n",
    "        train_attack = X_attack.loc[:,sens].values\n",
    "        model = Pipeline()\n",
    "        model.fit(train_normal,train_attack,lag,stride,optimal_k = k,tune=False,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T,\n",
    "                corr_attack=corr_attack[:,i].reshape(nolag_attack,len(X_attack.columns)).T)\n",
    "        test = X_test.loc[:,sens].values\n",
    "        y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "        sensor_predicted.append(y_predicted)\n",
    "        accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "        precision.append(precision_score(y_actual,y_predicted))\n",
    "        recall.append(recall_score(y_actual,y_predicted))\n",
    "        fscore.append(f1_score(y_actual,y_predicted))\n",
    "        sensor_models.append(model)    \n",
    "    sensor_predicted = np.asarray(sensor_predicted)\n",
    "    y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "    print(\"-------number of clusters------\", k)\n",
    "    print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "    print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "    print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "    print(\"F1-score \",f1_score(y_actual,y_predicted))\n",
    "    fscores_k_2.append(f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7076923076923076,\n",
       " 0.6666666666666667,\n",
       " 0.6461538461538462,\n",
       " 0.641025641025641,\n",
       " 0.6753246753246753,\n",
       " 0.6506024096385543]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscores_k_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + Threshold tuning (No concat of training and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------number of clusters------ 2\n",
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n",
      "-------number of clusters------ 3\n",
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n",
      "-------number of clusters------ 4\n",
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n",
      "-------number of clusters------ 5\n",
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n",
      "-------number of clusters------ 6\n",
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n",
      "-------number of clusters------ 7\n",
      "Accuracy  0.45588235294117646\n",
      "Precision  0.4393939393939394\n",
      "Recall  1.0\n",
      "F1-score  0.6105263157894737\n"
     ]
    }
   ],
   "source": [
    "fscores_k_3 = []\n",
    "for k in range(2,8):\n",
    "    sensor_models = []\n",
    "    sensor_predicted = []\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    fscore = []\n",
    "    for i,sens in enumerate(sensors):\n",
    "        train_normal = X_normal.loc[:,sens].values\n",
    "        train_attack = X_attack.loc[:,sens].values\n",
    "        model = Pipeline()\n",
    "        model.fit(train_normal,train_attack,lag,stride,optimal_k=k,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T,\n",
    "                corr_attack=corr_attack[:,i].reshape(nolag_attack,len(X_attack.columns)).T)\n",
    "        test = X_test.loc[:,sens].values\n",
    "        y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(len(X_normal.columns),nolag_test))\n",
    "        sensor_predicted.append(y_predicted)\n",
    "        accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "        precision.append(precision_score(y_actual,y_predicted))\n",
    "        recall.append(recall_score(y_actual,y_predicted))\n",
    "        fscore.append(f1_score(y_actual,y_predicted))\n",
    "        sensor_models.append(model)    \n",
    "    sensor_predicted = np.asarray(sensor_predicted)\n",
    "    y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "    print(\"-------number of clusters------\", k)\n",
    "    print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "    print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "    print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "    print(\"F1-score \",f1_score(y_actual,y_predicted))\n",
    "    fscores_k_3.append(f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5979381443298969,\n",
       " 0.5979381443298969,\n",
       " 0.5979381443298969,\n",
       " 0.5979381443298969,\n",
       " 0.5979381443298969,\n",
       " 0.6105263157894737]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscores_k_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
