{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/user/meepc\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import Hankel,Corrhankel,Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal = pd.read_csv('~/data/te/normal_training.csv')\n",
    "train_attack = pd.read_csv('~/data/te/attack_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [col for col in train_normal.columns if col not in ['faultNumber', 'simulationRun', 'sample','LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normal = pd.DataFrame(index=train_normal.index, columns=sensors, data=scaler.fit_transform(train_normal[sensors]))\n",
    "X_attack = pd.DataFrame(data=scaler.fit_transform(train_attack.loc[:,sensors]),index=train_attack.index,columns=sensors).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hankel = Hankel()\n",
    "corrhankel = Corrhankel()\n",
    "lag = 360\n",
    "stride = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_normal,nolag_normal = corrhankel.fit(X_normal.to_numpy(),lag,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_attack,nolag_attack = corrhankel.fit(X_attack.to_numpy(),lag,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_csv('~/data/te/normal_testing.csv')\n",
    "df_test2 = pd.read_csv('~/data/te/attack_testing.csv')\n",
    "df_test=pd.concat((df_test1,df_test2),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epasad with 1 cluster and no threshold tuning (training attack included in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.concat((df_test,train_attack),axis=0)\n",
    "X_test = pd.DataFrame(index=test_combined.index, columns=sensors, data=scaler.fit_transform(test_combined[sensors]))\n",
    "corr_test,nolag_test = corrhankel.fit(X_test.to_numpy(),lag,stride)\n",
    "Y_test = test_combined.loc[:,'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,optimal_k=1,tune=False,corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.963855421686747\n",
      "Precision  0.975609756097561\n",
      "Recall  0.9876543209876543\n",
      "F1-score  0.9815950920245398\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.23412882298424467 Median : 0.15060240963855423 Min : 0.07228915662650602 Max : 0.9036144578313253\n",
      "precision - Mean: 0.9964875320757673 Median : 1.0 Min : 0.9682539682539683 Max : 1.0\n",
      "recall -    Mean: 0.21830484330484332 Median : 0.12962962962962962 Min : 0.04938271604938271 Max : 0.9259259259259259\n",
      "f1 -        Mean: 0.3044526630255683 Median : 0.22950819672131148 Min : 0.09411764705882353 Max : 0.949367088607595\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + No threshold tuning (training attack mixed in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=False,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.7048192771084337\n",
      "Precision  0.9829059829059829\n",
      "Recall  0.7098765432098766\n",
      "F1-score  0.8243727598566307\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.126274328081557 Median : 0.11445783132530121 Min : 0.024096385542168676 Max : 0.4036144578313253\n",
      "precision - Mean: 0.903272101033295 Median : 1.0 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.10493827160493828 Median : 0.09259259259259259 Min : 0.0 Max : 0.4012345679012346\n",
      "f1 -        Mean: 0.18219731062228378 Median : 0.16943309499489273 Min : 0.0 Max : 0.5676855895196506\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epasad with 1 cluster : (training attack is not in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index=df_test.index, columns=sensors, data=scaler.fit_transform(df_test[sensors]))\n",
    "Y_test = df_test.loc[:,'LABEL']\n",
    "corr_test,nolag_test = corrhankel.fit(X_test.to_numpy(),lag,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models= []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,optimal_k=1,tune=False,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T,corr_attack=corr_attack[:,i].reshape(nolag_attack,len(X_attack.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test[:,i].reshape(nolag_test,len(X_test.columns)).T)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted)) \n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicitions = np.asarray(sensor_predicted)\n",
    "predicted_label=np.any(sensor_predicitions>0,axis=0).astype(int)\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9636363636363636\n",
      "Precision  0.9636363636363636\n",
      "Recall  1.0\n",
      "F1-score  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,predicted_label))\n",
    "print(\"Precision \",precision_score(y_actual,predicted_label))\n",
    "print(\"Recall \",recall_score(y_actual,predicted_label))\n",
    "print(\"F1-score \",f1_score(y_actual,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.24265734265734265 Median : 0.15454545454545454 Min : 0.08181818181818182 Max : 0.9090909090909091\n",
      "precision - Mean: 0.9948375155964226 Median : 1.0 Min : 0.9555555555555556 Max : 1.0\n",
      "recall -    Mean: 0.21879535558780844 Median : 0.12264150943396226 Min : 0.04716981132075472 Max : 0.9433962264150944\n",
      "f1 -        Mean: 0.301545478292115 Median : 0.21848739495798317 Min : 0.09009009009009009 Max : 0.9523809523809524\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + No threshold tuning (No concat of training and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index=df_test.index, columns=sensors, data=scaler.fit_transform(df_test[sensors]))\n",
    "corr_test,nolag_test = corrhankel.fit(X_test.to_numpy(),lag,stride)\n",
    "Y_test = df_test.loc[:,'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=False,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T,\n",
    "              corr_attack=corr_attack[:,i].reshape(nolag_attack,len(X_attack.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(nolag_test,len(X_normal.columns)).T)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8181818181818182\n",
      "Precision  0.967391304347826\n",
      "Recall  0.839622641509434\n",
      "F1-score  0.898989898989899\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + Threshold tuning (No concat of training and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,kscore_init='inertia',corr_normal=corr_normal[:,i].reshape(nolag_normal,len(X_normal.columns)).T,\n",
    "              corr_attack=corr_attack[:,i].reshape(nolag_attack,len(X_attack.columns)).T)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_test=corr_test[:,i].reshape(len(X_normal.columns),nolag_test))\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9636363636363636\n",
      "Precision  0.9636363636363636\n",
      "Recall  1.0\n",
      "F1-score  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.741083916083916 Median : 0.8727272727272728 Min : 0.2 Max : 0.9636363636363636\n",
      "precision - Mean: 0.9738798549444699 Median : 0.9654106858054227 Min : 0.9538461538461539 Max : 1.0\n",
      "recall -    Mean: 0.7554426705370101 Median : 0.8915094339622642 Min : 0.16981132075471697 Max : 1.0\n",
      "f1 -        Mean: 0.8119802403643042 Median : 0.9309105916053699 Min : 0.2903225806451613 Max : 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
