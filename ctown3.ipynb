{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import Hankel,Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('~/data/ctown/dataset03.csv')\n",
    "df2 = pd.read_csv('~/data/ctown/dataset04.csv')\n",
    "\n",
    "train_normal = pd.concat((df1,df2[df2['ATT_FLAG']==0]),axis=0,ignore_index=True)\n",
    "train_attack = df2[df2['ATT_FLAG']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = [col for col in train_normal.columns if col not in ['DATETIME','ATT_FLAG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normal = pd.DataFrame(index=train_normal.index, columns=sensors, data=scaler.fit_transform(train_normal[sensors]))\n",
    "X_attack = train_attack[sensors].reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hankel = Hankel()\n",
    "lag = 60\n",
    "stride = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('~/data/ctown/test_dataset.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epasad with 1 cluster and no threshold tuning (training attack included in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.concat((df_test,train_attack),axis=0)\n",
    "X_test = pd.DataFrame(index=test_combined.index, columns=sensors, data=scaler.fit_transform(test_combined[sensors]))\n",
    "Y_test = test_combined.loc[:,'ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for sens in sensors:\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,1,False)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.788235294117647\n",
      "Precision  0.7692307692307693\n",
      "Recall  0.8695652173913043\n",
      "F1-score  0.8163265306122449\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5028727770177839 Median : 0.5058823529411764 Min : 0.4470588235294118 Max : 0.6235294117647059\n",
      "precision - Mean: 0.6798311184939092 Median : 1.0 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.08998988877654196 Median : 0.08695652173913043 Min : 0.0 Max : 0.32608695652173914\n",
      "f1 -        Mean: 0.15410990256134335 Median : 0.16 Min : 0.0 Max : 0.48387096774193544\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + No threshold tuning (training attack mixed in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for sens in sensors:\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=False)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.5411764705882353\n",
      "Precision  0.5411764705882353\n",
      "Recall  1.0\n",
      "F1-score  0.7022900763358779\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5105335157318742 Median : 0.5058823529411764 Min : 0.43529411764705883 Max : 0.6470588235294118\n",
      "precision - Mean: 0.48810869247973887 Median : 0.5918367346938775 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.22093023255813954 Median : 0.2391304347826087 Min : 0.0 Max : 0.6304347826086957\n",
      "f1 -        Mean: 0.2842612930740881 Median : 0.36065573770491804 Min : 0.0 Max : 0.6105263157894736\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters + Threshold tuning (No concat of training and test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index=df_test.index, columns=sensors, data=scaler.fit_transform(df_test[sensors]))\n",
    "Y_test = df_test.loc[:,'ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models = []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for sens in sensors:\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride)\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test)\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted))\n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicted = np.asarray(sensor_predicted)\n",
    "y_predicted = np.any(sensor_predicted,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,y_predicted))\n",
    "print(\"Precision \",precision_score(y_actual,y_predicted))\n",
    "print(\"Recall \",recall_score(y_actual,y_predicted))\n",
    "print(\"F1-score \",f1_score(y_actual,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5656634746922024 Median : 0.5735294117647058 Min : 0.4852941176470588 Max : 0.6470588235294118\n",
      "precision - Mean: 0.34877877076101665 Median : 0.43478260869565216 Min : 0.0 Max : 0.75\n",
      "recall -    Mean: 0.19165998396150766 Median : 0.1724137931034483 Min : 0.0 Max : 0.5862068965517241\n",
      "f1 -        Mean: 0.22309983286002688 Median : 0.2702702702702703 Min : 0.0 Max : 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
