{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import Hankel,Rank,Cluster,Meepc,Pipeline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from scipy.linalg import hankel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('~/data/ctown/dataset03.csv')\n",
    "df_2 = pd.read_csv('~/data/ctown/dataset04.csv')\n",
    "train_normal=pd.concat((df_1,df_2[df_2['ATT_FLAG']==0]),axis=0,ignore_index=True)\n",
    "train_attack=df_2[df_2['ATT_FLAG']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hankel = Hankel()\n",
    "lag = 60\n",
    "stride = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors=[col for col in train_normal.columns if col not in ['DATETIME','ATT_FLAG']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>F_PU2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J300</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.810652</td>\n",
       "      <td>-0.840399</td>\n",
       "      <td>-1.489684</td>\n",
       "      <td>-1.438753</td>\n",
       "      <td>-0.125827</td>\n",
       "      <td>-0.299891</td>\n",
       "      <td>-2.102859</td>\n",
       "      <td>-0.192322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.701055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.485068</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>-0.467118</td>\n",
       "      <td>0.198329</td>\n",
       "      <td>-1.258253</td>\n",
       "      <td>0.754636</td>\n",
       "      <td>-1.256119</td>\n",
       "      <td>-0.150254</td>\n",
       "      <td>-1.034333</td>\n",
       "      <td>-0.359477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.891658</td>\n",
       "      <td>-0.867565</td>\n",
       "      <td>-0.824829</td>\n",
       "      <td>-1.366330</td>\n",
       "      <td>0.513682</td>\n",
       "      <td>0.702713</td>\n",
       "      <td>-1.754244</td>\n",
       "      <td>-0.182644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486352</td>\n",
       "      <td>1.186900</td>\n",
       "      <td>-0.470150</td>\n",
       "      <td>0.423304</td>\n",
       "      <td>-1.270108</td>\n",
       "      <td>0.771354</td>\n",
       "      <td>-1.267867</td>\n",
       "      <td>-0.140255</td>\n",
       "      <td>-1.042174</td>\n",
       "      <td>-0.371926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.968762</td>\n",
       "      <td>-0.883198</td>\n",
       "      <td>-0.091921</td>\n",
       "      <td>-0.577770</td>\n",
       "      <td>1.123162</td>\n",
       "      <td>0.731687</td>\n",
       "      <td>-1.280055</td>\n",
       "      <td>-0.249670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.484604</td>\n",
       "      <td>1.376971</td>\n",
       "      <td>-0.470137</td>\n",
       "      <td>0.513959</td>\n",
       "      <td>-1.100738</td>\n",
       "      <td>0.955519</td>\n",
       "      <td>-1.097261</td>\n",
       "      <td>0.847781</td>\n",
       "      <td>-1.042107</td>\n",
       "      <td>-0.371820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.958116</td>\n",
       "      <td>-0.867475</td>\n",
       "      <td>0.693507</td>\n",
       "      <td>0.327115</td>\n",
       "      <td>1.636865</td>\n",
       "      <td>0.731687</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>-0.333661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451086</td>\n",
       "      <td>1.558821</td>\n",
       "      <td>-0.437744</td>\n",
       "      <td>0.705006</td>\n",
       "      <td>0.355822</td>\n",
       "      <td>-0.980130</td>\n",
       "      <td>0.350843</td>\n",
       "      <td>1.572762</td>\n",
       "      <td>-1.019584</td>\n",
       "      <td>-0.336060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.832527</td>\n",
       "      <td>-0.813155</td>\n",
       "      <td>1.524846</td>\n",
       "      <td>1.560727</td>\n",
       "      <td>1.028078</td>\n",
       "      <td>0.731687</td>\n",
       "      <td>1.359430</td>\n",
       "      <td>-0.355917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395961</td>\n",
       "      <td>1.780926</td>\n",
       "      <td>-0.383674</td>\n",
       "      <td>1.024098</td>\n",
       "      <td>0.396924</td>\n",
       "      <td>-0.972501</td>\n",
       "      <td>0.391854</td>\n",
       "      <td>1.653455</td>\n",
       "      <td>-0.990238</td>\n",
       "      <td>-0.289469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>-0.026020</td>\n",
       "      <td>-0.622019</td>\n",
       "      <td>-0.519318</td>\n",
       "      <td>-0.979847</td>\n",
       "      <td>1.456856</td>\n",
       "      <td>-2.422136</td>\n",
       "      <td>-1.347590</td>\n",
       "      <td>1.901208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.641849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123946</td>\n",
       "      <td>-1.108734</td>\n",
       "      <td>-0.143233</td>\n",
       "      <td>0.189478</td>\n",
       "      <td>-1.360548</td>\n",
       "      <td>0.723200</td>\n",
       "      <td>-1.357927</td>\n",
       "      <td>-0.354694</td>\n",
       "      <td>-0.918065</td>\n",
       "      <td>-0.174880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>-0.367893</td>\n",
       "      <td>-0.492759</td>\n",
       "      <td>-1.152625</td>\n",
       "      <td>-1.202467</td>\n",
       "      <td>1.280082</td>\n",
       "      <td>-1.971590</td>\n",
       "      <td>-1.612310</td>\n",
       "      <td>1.805874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.641849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018536</td>\n",
       "      <td>-1.277789</td>\n",
       "      <td>-0.040691</td>\n",
       "      <td>0.099141</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>-1.362938</td>\n",
       "      <td>0.206009</td>\n",
       "      <td>-0.194622</td>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.058695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>-0.643058</td>\n",
       "      <td>-0.356696</td>\n",
       "      <td>-1.844844</td>\n",
       "      <td>-2.000190</td>\n",
       "      <td>-0.066119</td>\n",
       "      <td>-1.295771</td>\n",
       "      <td>-1.732637</td>\n",
       "      <td>1.963771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.641849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360210</td>\n",
       "      <td>0.735496</td>\n",
       "      <td>-0.340993</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-1.492194</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>-0.347161</td>\n",
       "      <td>-0.965277</td>\n",
       "      <td>-0.249839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12444</th>\n",
       "      <td>-0.968254</td>\n",
       "      <td>-0.519972</td>\n",
       "      <td>-1.285178</td>\n",
       "      <td>-2.853569</td>\n",
       "      <td>-1.439516</td>\n",
       "      <td>-1.521044</td>\n",
       "      <td>-2.310208</td>\n",
       "      <td>1.895249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.641849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730962</td>\n",
       "      <td>0.796970</td>\n",
       "      <td>-0.729189</td>\n",
       "      <td>2.778709</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>-1.547303</td>\n",
       "      <td>0.064038</td>\n",
       "      <td>-0.283132</td>\n",
       "      <td>-1.130522</td>\n",
       "      <td>-0.512194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>-1.318464</td>\n",
       "      <td>-0.792099</td>\n",
       "      <td>-0.696055</td>\n",
       "      <td>-1.554950</td>\n",
       "      <td>-1.589094</td>\n",
       "      <td>-1.352089</td>\n",
       "      <td>-2.550863</td>\n",
       "      <td>1.926034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.641849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.778215</td>\n",
       "      <td>1.143355</td>\n",
       "      <td>-0.780460</td>\n",
       "      <td>3.081605</td>\n",
       "      <td>-1.426227</td>\n",
       "      <td>0.620997</td>\n",
       "      <td>-1.421025</td>\n",
       "      <td>-0.113645</td>\n",
       "      <td>-1.184816</td>\n",
       "      <td>-0.598397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12446 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           L_T1      L_T2      L_T3      L_T4      L_T5      L_T6      L_T7  \\\n",
       "0     -1.810652 -0.840399 -1.489684 -1.438753 -0.125827 -0.299891 -2.102859   \n",
       "1     -1.891658 -0.867565 -0.824829 -1.366330  0.513682  0.702713 -1.754244   \n",
       "2     -1.968762 -0.883198 -0.091921 -0.577770  1.123162  0.731687 -1.280055   \n",
       "3     -1.958116 -0.867475  0.693507  0.327115  1.636865  0.731687 -0.127985   \n",
       "4     -1.832527 -0.813155  1.524846  1.560727  1.028078  0.731687  1.359430   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12441 -0.026020 -0.622019 -0.519318 -0.979847  1.456856 -2.422136 -1.347590   \n",
       "12442 -0.367893 -0.492759 -1.152625 -1.202467  1.280082 -1.971590 -1.612310   \n",
       "12443 -0.643058 -0.356696 -1.844844 -2.000190 -0.066119 -1.295771 -1.732637   \n",
       "12444 -0.968254 -0.519972 -1.285178 -2.853569 -1.439516 -1.521044 -2.310208   \n",
       "12445 -1.318464 -0.792099 -0.696055 -1.554950 -1.589094 -1.352089 -2.550863   \n",
       "\n",
       "          F_PU1  S_PU1     F_PU2  ...    P_J300    P_J256    P_J289    P_J415  \\\n",
       "0     -0.192322    0.0  0.701055  ... -0.485068  0.969072 -0.467118  0.198329   \n",
       "1     -0.182644    0.0  0.703361  ... -0.486352  1.186900 -0.470150  0.423304   \n",
       "2     -0.249670    0.0  0.687387  ... -0.484604  1.376971 -0.470137  0.513959   \n",
       "3     -0.333661    0.0  0.667368  ... -0.451086  1.558821 -0.437744  0.705006   \n",
       "4     -0.355917    0.0  0.662064  ... -0.395961  1.780926 -0.383674  1.024098   \n",
       "...         ...    ...       ...  ...       ...       ...       ...       ...   \n",
       "12441  1.901208    0.0 -1.641849  ... -0.123946 -1.108734 -0.143233  0.189478   \n",
       "12442  1.805874    0.0 -1.641849  ... -0.018536 -1.277789 -0.040691  0.099141   \n",
       "12443  1.963771    0.0 -1.641849  ... -0.360210  0.735496 -0.340993  0.014118   \n",
       "12444  1.895249    0.0 -1.641849  ... -0.730962  0.796970 -0.729189  2.778709   \n",
       "12445  1.926034    0.0 -1.641849  ... -0.778215  1.143355 -0.780460  3.081605   \n",
       "\n",
       "         P_J302    P_J306    P_J307    P_J317     P_J14    P_J422  \n",
       "0     -1.258253  0.754636 -1.256119 -0.150254 -1.034333 -0.359477  \n",
       "1     -1.270108  0.771354 -1.267867 -0.140255 -1.042174 -0.371926  \n",
       "2     -1.100738  0.955519 -1.097261  0.847781 -1.042107 -0.371820  \n",
       "3      0.355822 -0.980130  0.350843  1.572762 -1.019584 -0.336060  \n",
       "4      0.396924 -0.972501  0.391854  1.653455 -0.990238 -0.289469  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "12441 -1.360548  0.723200 -1.357927 -0.354694 -0.918065 -0.174880  \n",
       "12442  0.213483 -1.362938  0.206009 -0.194622 -0.844885 -0.058695  \n",
       "12443  0.000592 -1.492194 -0.005821 -0.347161 -0.965277 -0.249839  \n",
       "12444  0.070801 -1.547303  0.064038 -0.283132 -1.130522 -0.512194  \n",
       "12445 -1.426227  0.620997 -1.421025 -0.113645 -1.184816 -0.598397  \n",
       "\n",
       "[12446 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_normal=pd.DataFrame(data=scaler.fit_transform(train_normal.loc[:,sensors]),index=train_normal.index,columns=sensors)\n",
    "X_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>13/09/16 23</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.97</td>\n",
       "      <td>2.84</td>\n",
       "      <td>93.19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>86.28</td>\n",
       "      <td>22.50</td>\n",
       "      <td>82.83</td>\n",
       "      <td>16.84</td>\n",
       "      <td>79.83</td>\n",
       "      <td>16.56</td>\n",
       "      <td>80.37</td>\n",
       "      <td>39.76</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>14/09/16 00</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.68</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.23</td>\n",
       "      <td>3.13</td>\n",
       "      <td>91.44</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.84</td>\n",
       "      <td>21.86</td>\n",
       "      <td>83.52</td>\n",
       "      <td>29.21</td>\n",
       "      <td>85.83</td>\n",
       "      <td>29.21</td>\n",
       "      <td>54.31</td>\n",
       "      <td>41.20</td>\n",
       "      <td>23.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>14/09/16 01</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4.44</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.47</td>\n",
       "      <td>3.45</td>\n",
       "      <td>90.22</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.25</td>\n",
       "      <td>21.13</td>\n",
       "      <td>84.47</td>\n",
       "      <td>29.89</td>\n",
       "      <td>86.62</td>\n",
       "      <td>29.89</td>\n",
       "      <td>55.20</td>\n",
       "      <td>41.96</td>\n",
       "      <td>22.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>14/09/16 02</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.89</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.95</td>\n",
       "      <td>94.77</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.25</td>\n",
       "      <td>25.83</td>\n",
       "      <td>86.16</td>\n",
       "      <td>28.10</td>\n",
       "      <td>86.30</td>\n",
       "      <td>28.10</td>\n",
       "      <td>57.49</td>\n",
       "      <td>28.88</td>\n",
       "      <td>27.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>14/09/16 03</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.36</td>\n",
       "      <td>4.78</td>\n",
       "      <td>94.80</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>76.13</td>\n",
       "      <td>27.65</td>\n",
       "      <td>88.04</td>\n",
       "      <td>18.20</td>\n",
       "      <td>83.38</td>\n",
       "      <td>17.95</td>\n",
       "      <td>85.43</td>\n",
       "      <td>30.34</td>\n",
       "      <td>29.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4032</th>\n",
       "      <td>19/12/16 00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.28</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.77</td>\n",
       "      <td>98.55</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.52</td>\n",
       "      <td>28.10</td>\n",
       "      <td>86.71</td>\n",
       "      <td>19.27</td>\n",
       "      <td>82.66</td>\n",
       "      <td>19.16</td>\n",
       "      <td>70.54</td>\n",
       "      <td>30.92</td>\n",
       "      <td>30.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>19/12/16 01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.31</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.27</td>\n",
       "      <td>97.42</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.62</td>\n",
       "      <td>28.09</td>\n",
       "      <td>85.77</td>\n",
       "      <td>26.08</td>\n",
       "      <td>62.67</td>\n",
       "      <td>25.97</td>\n",
       "      <td>73.59</td>\n",
       "      <td>30.95</td>\n",
       "      <td>30.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>19/12/16 02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.61</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.95</td>\n",
       "      <td>96.87</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.70</td>\n",
       "      <td>28.10</td>\n",
       "      <td>87.05</td>\n",
       "      <td>29.10</td>\n",
       "      <td>62.90</td>\n",
       "      <td>29.10</td>\n",
       "      <td>60.38</td>\n",
       "      <td>30.96</td>\n",
       "      <td>30.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>19/12/16 03</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.68</td>\n",
       "      <td>5.33</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.22</td>\n",
       "      <td>3.65</td>\n",
       "      <td>95.94</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>76.64</td>\n",
       "      <td>29.24</td>\n",
       "      <td>89.16</td>\n",
       "      <td>29.62</td>\n",
       "      <td>62.82</td>\n",
       "      <td>29.62</td>\n",
       "      <td>59.34</td>\n",
       "      <td>31.80</td>\n",
       "      <td>30.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>19/12/16 04</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.20</td>\n",
       "      <td>5.13</td>\n",
       "      <td>4.17</td>\n",
       "      <td>1.63</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.54</td>\n",
       "      <td>95.12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>75.68</td>\n",
       "      <td>31.92</td>\n",
       "      <td>69.26</td>\n",
       "      <td>27.32</td>\n",
       "      <td>62.84</td>\n",
       "      <td>27.21</td>\n",
       "      <td>71.45</td>\n",
       "      <td>34.17</td>\n",
       "      <td>33.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  S_PU1  \\\n",
       "1727  13/09/16 23  3.51  2.55  3.60  2.24  1.62  4.97  2.84  93.19      1   \n",
       "1728  14/09/16 00  3.66  1.68  4.00  2.23  1.98  5.23  3.13  91.44      1   \n",
       "1729  14/09/16 01  3.84  0.83  4.44  2.46  2.51  5.47  3.45  90.22      1   \n",
       "1730  14/09/16 02  3.81  0.65  4.89  2.93  3.07  5.50  3.95  94.77      1   \n",
       "1731  14/09/16 03  3.75  1.00  5.24  3.42  3.67  5.36  4.78  94.80      1   \n",
       "...           ...   ...   ...   ...   ...   ...   ...   ...    ...    ...   \n",
       "4032  19/12/16 00  0.39  3.81  4.02  3.28  4.00  5.50  3.77  98.55      1   \n",
       "4033  19/12/16 01  0.50  3.69  4.50  3.72  3.31  5.50  4.27  97.42      1   \n",
       "4034  19/12/16 02  0.66  3.61  4.97  3.90  2.61  5.50  4.95  96.87      1   \n",
       "4035  19/12/16 03  0.92  3.68  5.33  4.31  2.08  5.22  3.65  95.94      1   \n",
       "4036  19/12/16 04  1.23  4.20  5.13  4.17  1.63  4.95  2.54  95.12      1   \n",
       "\n",
       "      ...  P_J256  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  \\\n",
       "1727  ...   86.28   22.50   82.83   16.84   79.83   16.56   80.37  39.76   \n",
       "1728  ...   87.84   21.86   83.52   29.21   85.83   29.21   54.31  41.20   \n",
       "1729  ...   87.25   21.13   84.47   29.89   86.62   29.89   55.20  41.96   \n",
       "1730  ...   91.25   25.83   86.16   28.10   86.30   28.10   57.49  28.88   \n",
       "1731  ...   76.13   27.65   88.04   18.20   83.38   17.95   85.43  30.34   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...    ...   \n",
       "4032  ...   89.52   28.10   86.71   19.27   82.66   19.16   70.54  30.92   \n",
       "4033  ...   89.62   28.09   85.77   26.08   62.67   25.97   73.59  30.95   \n",
       "4034  ...   92.70   28.10   87.05   29.10   62.90   29.10   60.38  30.96   \n",
       "4035  ...   76.64   29.24   89.16   29.62   62.82   29.62   59.34  31.80   \n",
       "4036  ...   75.68   31.92   69.26   27.32   62.84   27.21   71.45  34.17   \n",
       "\n",
       "      P_J422  ATT_FLAG  \n",
       "1727   24.20         1  \n",
       "1728   23.54         1  \n",
       "1729   22.79         1  \n",
       "1730   27.98         1  \n",
       "1731   29.44         1  \n",
       "...      ...       ...  \n",
       "4032   30.02         1  \n",
       "4033   30.05         1  \n",
       "4034   30.06         1  \n",
       "4035   30.90         1  \n",
       "4036   33.27         1  \n",
       "\n",
       "[492 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>F_PU2</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J300</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.510851</td>\n",
       "      <td>-0.546397</td>\n",
       "      <td>-0.878085</td>\n",
       "      <td>-2.084040</td>\n",
       "      <td>-1.526839</td>\n",
       "      <td>-2.239309</td>\n",
       "      <td>-0.533841</td>\n",
       "      <td>-0.623119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548804</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.059407</td>\n",
       "      <td>0.794886</td>\n",
       "      <td>-2.054304</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>-1.323365</td>\n",
       "      <td>0.506761</td>\n",
       "      <td>-1.344766</td>\n",
       "      <td>1.507526</td>\n",
       "      <td>0.763488</td>\n",
       "      <td>-2.086719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.623110</td>\n",
       "      <td>-1.147382</td>\n",
       "      <td>-0.297260</td>\n",
       "      <td>-2.101038</td>\n",
       "      <td>-1.035659</td>\n",
       "      <td>-0.755638</td>\n",
       "      <td>-0.193180</td>\n",
       "      <td>-0.784230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506152</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.298174</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>-2.298500</td>\n",
       "      <td>0.105519</td>\n",
       "      <td>0.590949</td>\n",
       "      <td>1.095478</td>\n",
       "      <td>0.604112</td>\n",
       "      <td>-1.873753</td>\n",
       "      <td>0.980724</td>\n",
       "      <td>-2.343036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.757819</td>\n",
       "      <td>-1.734552</td>\n",
       "      <td>0.341648</td>\n",
       "      <td>-1.710086</td>\n",
       "      <td>-0.312534</td>\n",
       "      <td>0.613905</td>\n",
       "      <td>0.182722</td>\n",
       "      <td>-0.896547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476418</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.578631</td>\n",
       "      <td>0.907219</td>\n",
       "      <td>-2.577037</td>\n",
       "      <td>0.232052</td>\n",
       "      <td>0.696182</td>\n",
       "      <td>1.172992</td>\n",
       "      <td>0.708874</td>\n",
       "      <td>-1.758276</td>\n",
       "      <td>1.095377</td>\n",
       "      <td>-2.634306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735368</td>\n",
       "      <td>-1.858894</td>\n",
       "      <td>0.995076</td>\n",
       "      <td>-0.911185</td>\n",
       "      <td>0.451524</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.770069</td>\n",
       "      <td>-0.477660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.797353</td>\n",
       "      <td>1.370448</td>\n",
       "      <td>-0.783719</td>\n",
       "      <td>0.457146</td>\n",
       "      <td>0.419171</td>\n",
       "      <td>1.141594</td>\n",
       "      <td>0.433104</td>\n",
       "      <td>-1.461149</td>\n",
       "      <td>-0.877852</td>\n",
       "      <td>-0.618722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.690464</td>\n",
       "      <td>-1.617118</td>\n",
       "      <td>1.503298</td>\n",
       "      <td>-0.078287</td>\n",
       "      <td>1.270157</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>1.745065</td>\n",
       "      <td>-0.474898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069683</td>\n",
       "      <td>-0.380559</td>\n",
       "      <td>-0.089286</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>-1.112899</td>\n",
       "      <td>0.855085</td>\n",
       "      <td>-1.130620</td>\n",
       "      <td>2.164060</td>\n",
       "      <td>-0.657599</td>\n",
       "      <td>-0.051718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-1.824121</td>\n",
       "      <td>0.323996</td>\n",
       "      <td>-0.268218</td>\n",
       "      <td>-0.316258</td>\n",
       "      <td>1.720405</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>0.558624</td>\n",
       "      <td>-0.129661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>1.170102</td>\n",
       "      <td>0.082415</td>\n",
       "      <td>0.530402</td>\n",
       "      <td>-0.947312</td>\n",
       "      <td>0.784439</td>\n",
       "      <td>-0.944206</td>\n",
       "      <td>0.232086</td>\n",
       "      <td>-0.570101</td>\n",
       "      <td>0.173530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-1.741798</td>\n",
       "      <td>0.241102</td>\n",
       "      <td>0.428772</td>\n",
       "      <td>0.431650</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>1.145971</td>\n",
       "      <td>-0.233692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>1.181682</td>\n",
       "      <td>0.078599</td>\n",
       "      <td>0.405202</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>-1.176969</td>\n",
       "      <td>0.104953</td>\n",
       "      <td>0.627823</td>\n",
       "      <td>-0.565575</td>\n",
       "      <td>0.185181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>-1.622056</td>\n",
       "      <td>0.185839</td>\n",
       "      <td>1.111241</td>\n",
       "      <td>0.737612</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>0.785098</td>\n",
       "      <td>1.944763</td>\n",
       "      <td>-0.284327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062966</td>\n",
       "      <td>1.538369</td>\n",
       "      <td>0.082415</td>\n",
       "      <td>0.575687</td>\n",
       "      <td>0.573926</td>\n",
       "      <td>-1.154401</td>\n",
       "      <td>0.587165</td>\n",
       "      <td>-1.086172</td>\n",
       "      <td>-0.564067</td>\n",
       "      <td>0.189065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>-1.427475</td>\n",
       "      <td>0.234194</td>\n",
       "      <td>1.633983</td>\n",
       "      <td>1.434527</td>\n",
       "      <td>-0.899221</td>\n",
       "      <td>-0.812702</td>\n",
       "      <td>0.417661</td>\n",
       "      <td>-0.369946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532920</td>\n",
       "      <td>-0.321497</td>\n",
       "      <td>0.517390</td>\n",
       "      <td>0.856722</td>\n",
       "      <td>0.654398</td>\n",
       "      <td>-1.162251</td>\n",
       "      <td>0.667277</td>\n",
       "      <td>-1.221112</td>\n",
       "      <td>-0.437345</td>\n",
       "      <td>0.515286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>-1.195475</td>\n",
       "      <td>0.593404</td>\n",
       "      <td>1.343571</td>\n",
       "      <td>1.196556</td>\n",
       "      <td>-1.513195</td>\n",
       "      <td>-2.353438</td>\n",
       "      <td>-0.886249</td>\n",
       "      <td>-0.445438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533467</td>\n",
       "      <td>-0.432672</td>\n",
       "      <td>1.539962</td>\n",
       "      <td>-1.793799</td>\n",
       "      <td>0.298462</td>\n",
       "      <td>-1.160288</td>\n",
       "      <td>0.295989</td>\n",
       "      <td>0.350158</td>\n",
       "      <td>-0.079811</td>\n",
       "      <td>1.435697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         L_T1      L_T2      L_T3      L_T4      L_T5      L_T6      L_T7  \\\n",
       "0    0.510851 -0.546397 -0.878085 -2.084040 -1.526839 -2.239309 -0.533841   \n",
       "1    0.623110 -1.147382 -0.297260 -2.101038 -1.035659 -0.755638 -0.193180   \n",
       "2    0.757819 -1.734552  0.341648 -1.710086 -0.312534  0.613905  0.182722   \n",
       "3    0.735368 -1.858894  0.995076 -0.911185  0.451524  0.785098  0.770069   \n",
       "4    0.690464 -1.617118  1.503298 -0.078287  1.270157 -0.013802  1.745065   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "487 -1.824121  0.323996 -0.268218 -0.316258  1.720405  0.785098  0.558624   \n",
       "488 -1.741798  0.241102  0.428772  0.431650  0.778977  0.785098  1.145971   \n",
       "489 -1.622056  0.185839  1.111241  0.737612 -0.176095  0.785098  1.944763   \n",
       "490 -1.427475  0.234194  1.633983  1.434527 -0.899221 -0.812702  0.417661   \n",
       "491 -1.195475  0.593404  1.343571  1.196556 -1.513195 -2.353438 -0.886249   \n",
       "\n",
       "        F_PU1  S_PU1     F_PU2  ...    P_J300    P_J256    P_J289    P_J415  \\\n",
       "0   -0.623119    0.0  0.548804  ... -2.059407  0.794886 -2.054304  0.013617   \n",
       "1   -0.784230    0.0  0.506152  ... -2.298174  0.975545 -2.298500  0.105519   \n",
       "2   -0.896547    0.0  0.476418  ... -2.578631  0.907219 -2.577037  0.232052   \n",
       "3   -0.477660    0.0  0.587312  ... -0.797353  1.370448 -0.783719  0.457146   \n",
       "4   -0.474898    0.0  0.587799  ... -0.069683 -0.380559 -0.089286  0.707547   \n",
       "..        ...    ...       ...  ...       ...       ...       ...       ...   \n",
       "487 -0.129661    0.0  0.679439  ...  0.059176  1.170102  0.082415  0.530402   \n",
       "488 -0.233692    0.0  0.651898  ...  0.055386  1.181682  0.078599  0.405202   \n",
       "489 -0.284327    0.0  0.638493  ...  0.062966  1.538369  0.082415  0.575687   \n",
       "490 -0.369946    0.0  0.615827  ...  0.532920 -0.321497  0.517390  0.856722   \n",
       "491 -0.445438    0.0  0.595842  ...  1.533467 -0.432672  1.539962 -1.793799   \n",
       "\n",
       "       P_J302    P_J306    P_J307    P_J317     P_J14    P_J422  \n",
       "0   -1.323365  0.506761 -1.344766  1.507526  0.763488 -2.086719  \n",
       "1    0.590949  1.095478  0.604112 -1.873753  0.980724 -2.343036  \n",
       "2    0.696182  1.172992  0.708874 -1.758276  1.095377 -2.634306  \n",
       "3    0.419171  1.141594  0.433104 -1.461149 -0.877852 -0.618722  \n",
       "4   -1.112899  0.855085 -1.130620  2.164060 -0.657599 -0.051718  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "487 -0.947312  0.784439 -0.944206  0.232086 -0.570101  0.173530  \n",
       "488  0.106567 -1.176969  0.104953  0.627823 -0.565575  0.185181  \n",
       "489  0.573926 -1.154401  0.587165 -1.086172 -0.564067  0.189065  \n",
       "490  0.654398 -1.162251  0.667277 -1.221112 -0.437345  0.515286  \n",
       "491  0.298462 -1.160288  0.295989  0.350158 -0.079811  1.435697  \n",
       "\n",
       "[492 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_attack=pd.DataFrame(data=scaler.fit_transform(train_attack.loc[:,sensors]),index=train_attack.index,columns=sensors).reset_index().drop(columns=['index'])\n",
    "X_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/01/17 00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.28</td>\n",
       "      <td>98.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.54</td>\n",
       "      <td>26.74</td>\n",
       "      <td>84.52</td>\n",
       "      <td>19.43</td>\n",
       "      <td>83.27</td>\n",
       "      <td>19.33</td>\n",
       "      <td>71.33</td>\n",
       "      <td>29.61</td>\n",
       "      <td>28.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/01/17 01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.78</td>\n",
       "      <td>97.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.43</td>\n",
       "      <td>26.73</td>\n",
       "      <td>85.04</td>\n",
       "      <td>25.97</td>\n",
       "      <td>64.22</td>\n",
       "      <td>25.86</td>\n",
       "      <td>73.79</td>\n",
       "      <td>29.63</td>\n",
       "      <td>28.73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/01/17 02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.31</td>\n",
       "      <td>5.03</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.32</td>\n",
       "      <td>5.16</td>\n",
       "      <td>3.22</td>\n",
       "      <td>96.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.72</td>\n",
       "      <td>26.89</td>\n",
       "      <td>87.16</td>\n",
       "      <td>29.18</td>\n",
       "      <td>63.81</td>\n",
       "      <td>29.18</td>\n",
       "      <td>59.05</td>\n",
       "      <td>29.80</td>\n",
       "      <td>28.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/01/17 03</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.54</td>\n",
       "      <td>5.16</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.82</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2.54</td>\n",
       "      <td>96.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.12</td>\n",
       "      <td>28.23</td>\n",
       "      <td>88.83</td>\n",
       "      <td>26.53</td>\n",
       "      <td>63.42</td>\n",
       "      <td>26.41</td>\n",
       "      <td>70.92</td>\n",
       "      <td>30.80</td>\n",
       "      <td>29.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/01/17 04</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.99</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.27</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.41</td>\n",
       "      <td>94.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>69.55</td>\n",
       "      <td>27.46</td>\n",
       "      <td>63.43</td>\n",
       "      <td>27.34</td>\n",
       "      <td>70.88</td>\n",
       "      <td>33.61</td>\n",
       "      <td>32.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>31/03/17 20</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.09</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>4.96</td>\n",
       "      <td>2.09</td>\n",
       "      <td>120.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.07</td>\n",
       "      <td>27.15</td>\n",
       "      <td>84.05</td>\n",
       "      <td>18.28</td>\n",
       "      <td>80.39</td>\n",
       "      <td>18.17</td>\n",
       "      <td>65.97</td>\n",
       "      <td>29.66</td>\n",
       "      <td>28.76</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>31/03/17 21</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.27</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.07</td>\n",
       "      <td>5.02</td>\n",
       "      <td>1.84</td>\n",
       "      <td>122.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.29</td>\n",
       "      <td>27.08</td>\n",
       "      <td>83.12</td>\n",
       "      <td>17.04</td>\n",
       "      <td>79.84</td>\n",
       "      <td>16.93</td>\n",
       "      <td>66.14</td>\n",
       "      <td>29.53</td>\n",
       "      <td>28.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>31/03/17 22</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.34</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1.78</td>\n",
       "      <td>122.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.08</td>\n",
       "      <td>26.20</td>\n",
       "      <td>83.77</td>\n",
       "      <td>16.97</td>\n",
       "      <td>80.25</td>\n",
       "      <td>16.86</td>\n",
       "      <td>66.29</td>\n",
       "      <td>28.98</td>\n",
       "      <td>28.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>31/03/17 23</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.44</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.67</td>\n",
       "      <td>5.24</td>\n",
       "      <td>1.82</td>\n",
       "      <td>98.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.85</td>\n",
       "      <td>26.59</td>\n",
       "      <td>84.07</td>\n",
       "      <td>19.00</td>\n",
       "      <td>81.37</td>\n",
       "      <td>18.89</td>\n",
       "      <td>66.07</td>\n",
       "      <td>29.49</td>\n",
       "      <td>28.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>01/04/17 00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.02</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.62</td>\n",
       "      <td>98.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.58</td>\n",
       "      <td>26.60</td>\n",
       "      <td>84.79</td>\n",
       "      <td>19.29</td>\n",
       "      <td>82.56</td>\n",
       "      <td>19.18</td>\n",
       "      <td>68.10</td>\n",
       "      <td>29.48</td>\n",
       "      <td>28.58</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2089 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7   F_PU1  S_PU1  \\\n",
       "0     04/01/17 00  0.73  2.27  4.00  3.26  3.87  5.50  4.28   98.93    1.0   \n",
       "1     04/01/17 01  0.69  2.25  4.53  3.26  3.84  5.50  4.78   97.95    1.0   \n",
       "2     04/01/17 02  0.90  2.31  5.03  3.41  3.32  5.16  3.22   96.82    1.0   \n",
       "3     04/01/17 03  1.11  2.54  5.16  3.97  2.82  5.01  2.54   96.76    1.0   \n",
       "4     04/01/17 04  1.27  2.99  4.94  4.27  2.35  5.38  3.41   94.77    1.0   \n",
       "...           ...   ...   ...   ...   ...   ...   ...   ...     ...    ...   \n",
       "2084  31/03/17 20  1.94  2.09  3.67  2.95  1.74  4.96  2.09  120.00    1.0   \n",
       "2085  31/03/17 21  1.54  2.27  3.24  2.84  2.07  5.02  1.84  122.23    1.0   \n",
       "2086  31/03/17 22  1.07  2.24  2.99  2.30  2.34  5.12  1.78  122.44    1.0   \n",
       "2087  31/03/17 23  0.85  2.14  3.44  2.35  2.67  5.24  1.82   98.71    1.0   \n",
       "2088  01/04/17 00  0.74  2.11  3.89  2.44  3.02  5.29  1.62   98.57    1.0   \n",
       "\n",
       "      ...  P_J256  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  \\\n",
       "0     ...   90.54   26.74   84.52   19.43   83.27   19.33   71.33  29.61   \n",
       "1     ...   90.43   26.73   85.04   25.97   64.22   25.86   73.79  29.63   \n",
       "2     ...   91.72   26.89   87.16   29.18   63.81   29.18   59.05  29.80   \n",
       "3     ...   76.12   28.23   88.83   26.53   63.42   26.41   70.92  30.80   \n",
       "4     ...   75.68   31.32   69.55   27.46   63.43   27.34   70.88  33.61   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...    ...   \n",
       "2084  ...   70.07   27.15   84.05   18.28   80.39   18.17   65.97  29.66   \n",
       "2085  ...   68.29   27.08   83.12   17.04   79.84   16.93   66.14  29.53   \n",
       "2086  ...   87.08   26.20   83.77   16.97   80.25   16.86   66.29  28.98   \n",
       "2087  ...   87.85   26.59   84.07   19.00   81.37   18.89   66.07  29.49   \n",
       "2088  ...   90.58   26.60   84.79   19.29   82.56   19.18   68.10  29.48   \n",
       "\n",
       "      P_J422  ATT_FLAG  \n",
       "0      28.71       0.0  \n",
       "1      28.73       0.0  \n",
       "2      28.90       0.0  \n",
       "3      29.90       0.0  \n",
       "4      32.71       0.0  \n",
       "...      ...       ...  \n",
       "2084   28.76       0.0  \n",
       "2085   28.63       0.0  \n",
       "2086   28.08       0.0  \n",
       "2087   28.59       0.0  \n",
       "2088   28.58       0.0  \n",
       "\n",
       "[2089 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('~/data/ctown/test_dataset.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.concat((df_test,train_attack),axis=0)\n",
    "X_test = pd.DataFrame(index=test_combined.index, columns=sensors, data=scaler.fit_transform(test_combined[sensors]))\n",
    "Y_test = test_combined.loc[:,'ATT_FLAG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)\n",
    "y_actual"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epasad with 1 cluster and no threshold tuning (training attack included in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99975431, -0.11939323,  0.0132175 , ..., -0.1200997 ,\n",
       "         0.41709521, -0.17490377],\n",
       "       [-0.11939323,  0.99973608, -0.22478237, ..., -0.19288438,\n",
       "         0.13926521,  0.55206976],\n",
       "       [ 0.0132175 , -0.22478237,  0.9997442 , ...,  0.06006327,\n",
       "        -0.21635736,  0.29343654],\n",
       "       ...,\n",
       "       [-0.04120527, -0.0786066 ,  0.21088941, ...,  0.9997529 ,\n",
       "         0.06519974, -0.11541525],\n",
       "       [ 0.31628084,  0.27729345,  0.03412865, ...,  0.06519974,\n",
       "         0.99976571, -0.5360726 ],\n",
       "       [-0.31985608,  0.43229072,  0.0035636 , ..., -0.11541525,\n",
       "        -0.5360726 ,  0.99975246]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating correlation matrix\n",
    "from models import Corrhankel\n",
    "Corrhankel=Corrhankel()\n",
    "corr_matrix,no_of_lags=Corrhankel.fit(X_normal,lag,stride)\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99972853, -0.30040161, -0.15334892, ...,  0.01803456,\n",
       "         0.39308846, -0.23239029],\n",
       "       [-0.30040161,  0.99970229, -0.29756778, ..., -0.21210024,\n",
       "        -0.04312965,  0.56030764],\n",
       "       [-0.15334892, -0.29756778,  0.99974192, ...,  0.08168724,\n",
       "        -0.36487259,  0.25634503],\n",
       "       ...,\n",
       "       [-0.19585698, -0.13535891,  0.02182073, ...,  0.99976245,\n",
       "        -0.24218295, -0.00930026],\n",
       "       [ 0.31882052,  0.32105398, -0.2440933 , ..., -0.24218295,\n",
       "         0.99961919, -0.21019683],\n",
       "       [-0.09485978,  0.61324711,  0.26869915, ..., -0.00930026,\n",
       "        -0.21019683,  0.9996613 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_test,no_of_lag_test=Corrhankel.fit(X_test,lag,stride)\n",
    "corr_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17759,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models= []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,optimal_k=1,tune=False,kscore_init='inertia',corr_normal=corr_matrix[:,i].reshape(len(X_normal.columns),no_of_lags))\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_matrix_test[:,i].reshape(len(X_test.columns),no_of_lag_test))\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted)) \n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicitions = np.asarray(sensor_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=np.any(sensor_predicitions>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.8\n",
      "Precision  0.8222222222222222\n",
      "Recall  0.8043478260869565\n",
      "F1-score  0.8131868131868132\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,predicted_label))\n",
    "print(\"Precision \",precision_score(y_actual,predicted_label))\n",
    "print(\"Recall \",recall_score(y_actual,predicted_label))\n",
    "print(\"F1-score \",f1_score(y_actual,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.49603283173734625 Median : 0.49411764705882355 Min : 0.4588235294117647 Max : 0.5764705882352941\n",
      "precision - Mean: 0.6645071982281284 Median : 1.0 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.07431749241658239 Median : 0.06521739130434782 Min : 0.0 Max : 0.2608695652173913\n",
      "f1 -        Mean: 0.12919362137574888 Median : 0.12244897959183672 Min : 0.0 Max : 0.39344262295081966\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters: no threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models= []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=False,kscore_init='inertia',corr_normal=corr_matrix[:,i].reshape(len(X_normal.columns),no_of_lags))\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_matrix_test[:,i].reshape(len(X_test.columns),no_of_lag_test))\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted)) \n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicitions = np.asarray(sensor_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=np.any(sensor_predicitions>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.6823529411764706\n",
      "Precision  0.6461538461538462\n",
      "Recall  0.9130434782608695\n",
      "F1-score  0.7567567567567568\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,predicted_label))\n",
    "print(\"Precision \",precision_score(y_actual,predicted_label))\n",
    "print(\"Recall \",recall_score(y_actual,predicted_label))\n",
    "print(\"F1-score \",f1_score(y_actual,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5047879616963066 Median : 0.5058823529411764 Min : 0.43529411764705883 Max : 0.6235294117647059\n",
      "precision - Mean: 0.6262649495207635 Median : 0.75 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.10920121334681496 Median : 0.10869565217391304 Min : 0.0 Max : 0.45652173913043476\n",
      "f1 -        Mean: 0.17781950611153438 Median : 0.18518518518518517 Min : 0.0 Max : 0.5675675675675675\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters: threshold tuning (training attack is not in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(index=df_test.index, columns=sensors, data=scaler.fit_transform(df_test[sensors]))\n",
    "Y_test = df_test.loc[:,'ATT_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.999734  , -0.30040247, -0.15334941, ...,  0.01803484,\n",
       "         0.39309793, -0.23239067],\n",
       "       [-0.30040247,  0.99970255, -0.29756794, ..., -0.21210297,\n",
       "        -0.04313057,  0.5603071 ],\n",
       "       [-0.15334941, -0.29756794,  0.99974277, ...,  0.08168831,\n",
       "        -0.36488054,  0.25634485],\n",
       "       ...,\n",
       "       [ 0.129464  , -0.21047769,  0.15952987, ...,  0.99975365,\n",
       "        -0.04180179, -0.29348887],\n",
       "       [ 0.37285663,  0.1631605 , -0.22335932, ..., -0.04180179,\n",
       "         0.99972783, -0.40038208],\n",
       "       [-0.43328583,  0.6072341 ,  0.37120681, ..., -0.29348887,\n",
       "        -0.40038208,  0.99972264]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_test,no_of_lag_test=Corrhankel.fit(X_test,lag,stride)\n",
    "corr_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hankel.fit(np.array(Y_test),lag,stride)\n",
    "y_actual = np.any(labels>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99972023, -0.29826368,  0.07099009, ..., -0.02939602,\n",
       "         0.4214424 , -0.29090008],\n",
       "       [-0.29826368,  0.99973707, -0.33004383, ...,  0.15301513,\n",
       "         0.11442202,  0.60549396],\n",
       "       [ 0.07099009, -0.33004383,  0.99973308, ...,  0.1443172 ,\n",
       "        -0.22035702,  0.10767704],\n",
       "       ...,\n",
       "       [-0.05014519, -0.22173059,  0.1579618 , ...,  0.99965917,\n",
       "        -0.20212494,  0.00349688],\n",
       "       [ 0.30376659,  0.34015882, -0.28873176, ..., -0.20212494,\n",
       "         0.99961723, -0.26046687],\n",
       "       [-0.31183093,  0.62548892,  0.38017901, ...,  0.00349688,\n",
       "        -0.26046687,  0.9997268 ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_attack,no_of_lag_attack=Corrhankel.fit(X_attack,lag,stride)\n",
    "corr_matrix_attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models= []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=True,kscore_init='inertia',corr_normal=corr_matrix[:,i].reshape(len(X_normal.columns),no_of_lags),corr_attack=corr_matrix_attack[:,i].reshape(len(X_attack.columns),no_of_lag_attack))\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_matrix_test[:,i].reshape(len(X_test.columns),no_of_lag_test))\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted)) \n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicitions = np.asarray(sensor_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=np.any(sensor_predicitions>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.5882352941176471\n",
      "Precision  1.0\n",
      "Recall  0.034482758620689655\n",
      "F1-score  0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,predicted_label))\n",
    "print(\"Precision \",precision_score(y_actual,predicted_label))\n",
    "print(\"Recall \",recall_score(y_actual,predicted_label))\n",
    "print(\"F1-score \",f1_score(y_actual,predicted_label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy  0.6823529411764706\n",
    "Precision  0.6338028169014085\n",
    "Recall  0.9782608695652174\n",
    "F1-score  0.7692307692307693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5738714090287278 Median : 0.5735294117647058 Min : 0.5735294117647058 Max : 0.5882352941176471\n",
      "precision - Mean: 0.023255813953488372 Median : 0.0 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.0008019246190858059 Median : 0.0 Min : 0.0 Max : 0.034482758620689655\n",
      "f1 -        Mean: 0.0015503875968992248 Median : 0.0 Min : 0.0 Max : 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_60102/668683560.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple clusters: threshold tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99975431, -0.11939323,  0.0132175 , ..., -0.1200997 ,\n",
       "         0.41709521, -0.17490377],\n",
       "       [-0.11939323,  0.99973608, -0.22478237, ..., -0.19288438,\n",
       "         0.13926521,  0.55206976],\n",
       "       [ 0.0132175 , -0.22478237,  0.9997442 , ...,  0.06006327,\n",
       "        -0.21635736,  0.29343654],\n",
       "       ...,\n",
       "       [-0.04120527, -0.0786066 ,  0.21088941, ...,  0.9997529 ,\n",
       "         0.06519974, -0.11541525],\n",
       "       [ 0.31628084,  0.27729345,  0.03412865, ...,  0.06519974,\n",
       "         0.99976571, -0.5360726 ],\n",
       "       [-0.31985608,  0.43229072,  0.0035636 , ..., -0.11541525,\n",
       "        -0.5360726 ,  0.99975246]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating correlation matrix\n",
    "from models import Corrhankel\n",
    "Corrhankel=Corrhankel()\n",
    "corr_matrix,no_of_lags=Corrhankel.fit(X_normal,lag,stride)\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.999734  , -0.30040247, -0.15334941, ...,  0.01803484,\n",
       "         0.39309793, -0.23239067],\n",
       "       [-0.30040247,  0.99970255, -0.29756794, ..., -0.21210297,\n",
       "        -0.04313057,  0.5603071 ],\n",
       "       [-0.15334941, -0.29756794,  0.99974277, ...,  0.08168831,\n",
       "        -0.36488054,  0.25634485],\n",
       "       ...,\n",
       "       [ 0.129464  , -0.21047769,  0.15952987, ...,  0.99975365,\n",
       "        -0.04180179, -0.29348887],\n",
       "       [ 0.37285663,  0.1631605 , -0.22335932, ..., -0.04180179,\n",
       "         0.99972783, -0.40038208],\n",
       "       [-0.43328583,  0.6072341 ,  0.37120681, ..., -0.29348887,\n",
       "        -0.40038208,  0.99972264]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_test,no_of_lag_test=Corrhankel.fit(X_test,lag,stride)\n",
    "corr_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2924, 43)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99754306e-01, -1.19393232e-01,  1.32174998e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -5.31053264e-03],\n",
       "       [-3.06354381e-02,  4.23070003e-30,  8.46140006e-30, ...,\n",
       "         3.14269026e-02, -1.01728145e-01,  0.00000000e+00],\n",
       "       [-1.03189250e-01, -7.41560148e-02,  0.00000000e+00, ...,\n",
       "        -3.11582361e-02, -2.07272653e-01, -6.27853435e-02],\n",
       "       ...,\n",
       "       [ 0.00000000e+00, -1.97528120e-01, -1.87844079e-01, ...,\n",
       "         6.72327269e-01, -1.50635002e-01, -3.74231788e-01],\n",
       "       [-1.38398932e-01, -3.79451973e-01, -2.88457817e-02, ...,\n",
       "        -2.02354682e-01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.73288162e-29, -8.66440810e-30, -8.88552870e-02, ...,\n",
       "        -4.12052715e-02,  3.16280840e-01, -3.19856079e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[:,0].reshape(len(X_normal.columns),no_of_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17759, 43)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99975431, -0.11939323,  0.0132175 , ..., -0.04120527,\n",
       "        0.31628084, -0.31985608])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17759,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_models= []\n",
    "sensor_predicted = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []\n",
    "for i,sens in enumerate(sensors):\n",
    "    train_normal = X_normal.loc[:,sens].values\n",
    "    train_attack = X_attack.loc[:,sens].values\n",
    "    model = Pipeline()\n",
    "    model.fit(train_normal,train_attack,lag,stride,tune=False,corr=corr_matrix[:,i].reshape(len(X_normal.columns),no_of_lags))\n",
    "    test = X_test.loc[:,sens].values\n",
    "    y_predicted = model.predict(test,corr_matrix_test[:,i].reshape(len(X_test.columns),no_of_lag_test))\n",
    "    sensor_predicted.append(y_predicted)\n",
    "    accuracy.append(accuracy_score(y_actual,y_predicted))\n",
    "    precision.append(precision_score(y_actual,y_predicted))\n",
    "    recall.append(recall_score(y_actual,y_predicted)) \n",
    "    fscore.append(f1_score(y_actual,y_predicted))\n",
    "    sensor_models.append(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_predicitions=np.asarray(sensor_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label=np.any(sensor_predicitions>0,axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.4264705882352941\n",
      "Precision  0.4264705882352941\n",
      "Recall  1.0\n",
      "F1-score  0.5979381443298969\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy \",accuracy_score(y_actual,predicted_label))\n",
    "print(\"Precision \",precision_score(y_actual,predicted_label))\n",
    "print(\"Recall \",recall_score(y_actual,predicted_label))\n",
    "print(\"F1-score \",f1_score(y_actual,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -  Mean: 0.5745554035567716 Median : 0.5735294117647058 Min : 0.47058823529411764 Max : 0.6470588235294118\n",
      "precision - Mean: 0.40353096987136333 Median : 0.47058823529411764 Min : 0.0 Max : 1.0\n",
      "recall -    Mean: 0.1491579791499599 Median : 0.10344827586206896 Min : 0.0 Max : 0.5517241379310345\n",
      "f1 -        Mean: 0.18889183948612184 Median : 0.17647058823529413 Min : 0.0 Max : 0.507936507936508\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy -  Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(accuracy).mean(), np.median(np.asarray(accuracy)),np.asarray(accuracy).min(), np.asarray(accuracy).max()))\n",
    "print(\"precision - Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(precision).mean(), np.median(np.asarray(precision)),np.asarray(precision).min(), np.asarray(precision).max()))\n",
    "print(\"recall -    Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(recall).mean(), np.median(np.asarray(recall)),np.asarray(recall).min(), np.asarray(recall).max()))\n",
    "print(\"f1 -        Mean: {} Median : {} Min : {} Max : {}\".format(np.asarray(fscore).mean(), np.median(np.asarray(fscore)),np.asarray(fscore).min(), np.asarray(fscore).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53b584fcbb4de26fd06ec6c2cdf5e79eeceea3a87d14166bd7f17bce6a8842a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
